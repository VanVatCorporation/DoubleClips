package com.vanvatcorporation.doubleclips;

import android.content.Context;

import com.arthenica.ffmpegkit.FFmpegKit;
import com.arthenica.ffmpegkit.ReturnCode;
import com.vanvatcorporation.doubleclips.activities.EditingActivity;
import com.vanvatcorporation.doubleclips.activities.MainActivity;
import com.vanvatcorporation.doubleclips.constants.Constants;
import com.vanvatcorporation.doubleclips.helper.IOHelper;
import com.vanvatcorporation.doubleclips.impl.java.RunnableImpl;
import com.vanvatcorporation.doubleclips.manager.LoggingManager;

import java.util.ArrayList;
import java.util.Objects;

public class FFmpegMethod {

    public static void applyGrayscaleFilter(Context context, String inputPath, String outputPath) {
        String command = "-i " + inputPath + " -vf hue=s=0 -c:a copy " + outputPath;
        runAnyCommand(context, command, "Video processed successfully!", "Failed: ", true);
    }


    public static void trimVideo(Context context, String inputPath, String outputPath, int startSeconds, int durationSeconds) {
        String command = String.format("-ss %d -i %s -t %d -c copy %s", startSeconds, inputPath, durationSeconds, outputPath);
        runAnyCommand(context, command, "Trim successful!", "Trim failed: ", true);
    }

    /*
    Example listFilePath.txt content
    file '/storage/emulated/0/Movies/part1.mp4'
file '/storage/emulated/0/Movies/part2.mp4'

    */
    public static void mergeVideos(Context context, String listFilePath, String outputPath) {
        String command = String.format("-f concat -safe 0 -i %s -c copy %s", listFilePath, outputPath);
        runAnyCommand(context, command, "Merge successful!", "Merge failed: ", true);
    }

    public static void addTextOverlay(Context context, String inputPath, String outputPath, String text) {
        String command = String.format(
                "-i %s -vf drawtext=text='%s':fontcolor=white:fontsize=24:x=(w-text_w)/2:y=(h-text_h)/2 -codec:a copy %s",
                inputPath, text, outputPath);
        runAnyCommand(context, command, "Text overlay added!", "Text overlay failed: ", true);
    }


    public static void runAnyCommand(Context context, String cmd) {
        runAnyCommand(context, cmd, "Ran command!", "Command failed: ", true);
    }

    public static void runAnyCommand(Context context, String cmd,
                                     Runnable onSuccessRunnable, Runnable onFailRunnable,
                                     RunnableImpl onLogRunnable, RunnableImpl onStatisticsRunnable) {
        runAnyCommand(context, cmd, "Ran command!", "Command failed: ", true, onSuccessRunnable, onFailRunnable, onLogRunnable, onStatisticsRunnable);
    }

    public static void runAnyCommand(Context context, String cmd, String successMessage, String failMessage, boolean includeFullReport) {
        runAnyCommand(context, cmd, successMessage, failMessage, includeFullReport, () -> {
        }, () -> {
        }, new RunnableImpl() {
            @Override
            public <T> void runWithParam(T param) {

            }
        }, new RunnableImpl() {
            @Override
            public <T> void runWithParam(T param) {

            }
        });
    }

    public static void runAnyCommand(Context context, String cmd, String successMessage, String failMessage, boolean includeFullReport,
                                     Runnable onSuccessRunnable, Runnable onFailRunnable,
                                     RunnableImpl onLogRunnable, RunnableImpl onStatisticsRunnable) {
        FFmpegKit.executeAsync(cmd, session -> {
                    if (ReturnCode.isSuccess(session.getReturnCode())) {
                        StringBuilder builder = new StringBuilder();
                        if (includeFullReport) {
                            builder.append("Report: ").append("\n")
                                    .append("Output: ").append(session.getOutput()).append("\n")
                                    .append("State: ").append(session.getState()).append("\n")
                                    .append("Return code: ").append(session.getReturnCode()).append("\n");
                        }
                        LoggingManager.LogToToast(context, successMessage + builder);
                        onSuccessRunnable.run();
                    } else {
                        StringBuilder builder = new StringBuilder();
                        if (includeFullReport) {
                            builder.append("Report: ").append("\n")
                                    .append("Output: ").append(session.getOutput()).append("\n")
                                    .append("State: ").append(session.getState()).append("\n")
                                    .append("Return code: ").append(session.getReturnCode()).append("\n")
                                    .append("Stacktracce: ").append(session.getFailStackTrace()).append("\n");
                        }
                        LoggingManager.LogToToast(context, failMessage + builder);
                        onFailRunnable.run();
                    }
                },
                onLogRunnable::runWithParam,
                onStatisticsRunnable::runWithParam
        );

    }


    public static void getFFmpegVersion(Context context) {
        String command = "-version";
        runAnyCommand(context, command);
    }


    public static void generatePreviewVideo(Context context, EditingActivity.Timeline timeline, EditingActivity.VideoSettings settings, MainActivity.ProjectData data, Runnable onSuccess) {
        runAnyCommand(context, generatePreviewCmd(settings, timeline, data), onSuccess, () -> {
                },
                new RunnableImpl() {
                    @Override
                    public <T> void runWithParam(T param) {

                    }
                }, new RunnableImpl() {
                    @Override
                    public <T> void runWithParam(T param) {

                    }
                });
    }


    public static String generatePreviewCmd(EditingActivity.VideoSettings settings, EditingActivity.Timeline timeline, MainActivity.ProjectData data) {
        StringBuilder cmd = new StringBuilder();
        cmd.append("-f lavfi -i color=c=black:s=")
                .append(settings.getVideoWidth()).append("x").append(settings.getVideoHeight())
                .append(":r=").append(settings.getFrameRate())
                .append(" -t ").append(timeline.duration).append(" ");


        int inputIndex = 1;
        StringBuilder filterComplex = new StringBuilder();
        filterComplex.append("[0:v]trim=duration=").append(timeline.duration).append(",setpts=PTS-STARTPTS[base];");

        for (EditingActivity.Track track : timeline.tracks) {
            for (EditingActivity.Clip clip : track.clips) {
                cmd.append("-i ").append("\"").append(clip.filePath).append("\"").append(" ");

                String label = "[clip" + inputIndex + "]";
                String scaled = "[scaled" + inputIndex + "]";
                String rotated = "[rotated" + inputIndex + "]";

                filterComplex.append("[").append(inputIndex).append(":v]")
                        .append("scale=iw*").append(clip.scaleX).append(":ih*").append(clip.scaleY).append(",")
                        .append("rotate=").append(clip.rotation).append(":ow=rotw(").append(clip.rotation).append("):oh=roth(").append(clip.rotation).append("),")
                        //.append("trim=start=").append(0).append(":end=").append(clip.duration).append(",")//Inner clip to trim from leftHandle / rightHandle

                        .append("trim=start=").append(clip.startClipTrim).append(":end=").append(clip.duration + clip.startClipTrim).append(",")
                        .append("setpts=PTS-STARTPTS+").append(clip.startTime).append("/TB").append(label).append(";");

                String overlayLabel = inputIndex == 1 ? "[base]" : "[tmp" + (inputIndex - 1) + "]";
                String outLabel = "[tmp" + inputIndex + "]";

                filterComplex.append(overlayLabel).append(label)
                        .append("overlay=")
                        .append(clip.posX).append(":").append(clip.posY)
                        .append(":enable='between(t,")
                        .append(clip.startTime).append(",")
                        .append(clip.startTime + clip.duration).append(")'")
                        .append(outLabel).append(";");

                inputIndex++;
            }
        }

        //  --------------------------------------- Audio Part -filter-complex ---------------------------------------

        StringBuilder audioInputs = new StringBuilder();
        StringBuilder audioMaps = new StringBuilder();

        int audioIndex = 1;
        int audioClipCount = 0;

        for (EditingActivity.Track track : timeline.tracks) {
            for (EditingActivity.Clip clip : track.clips) {
                int delayMs = (int) (clip.startTime * 1000);

                String audioLabel = "[a" + audioIndex + "]";
                String trimmedLabel = "[atrim" + audioIndex + "]";
                String delayedLabel = "[adelay" + audioIndex + "]";

                System.err.println(clip.startClipTrim + " - " + (clip.duration + clip.startClipTrim));
                filterComplex.append("[").append(audioIndex).append(":a]")
                        .append("atrim=start=").append(clip.startClipTrim).append(":end=").append(clip.duration + clip.startClipTrim).append(",")
                        .append("asetpts=PTS-STARTPTS").append(trimmedLabel).append(";");

                filterComplex.append(trimmedLabel)
                        .append("adelay=").append(delayMs).append("|").append(delayMs)
                        .append(delayedLabel).append(";");

                audioInputs.append(delayedLabel);
                audioIndex++;
                audioClipCount++;
            }
        }

        if (audioClipCount > 0) {
            filterComplex.append(audioInputs)
                    .append("amix=inputs=").append(audioClipCount)
                    .append("[aout];");
            audioMaps.append("-map \"[aout]\" ");
        } else {
            audioMaps.append("-an "); // No audio
        }
        //  --------------------------------------- End Audio Part -filter-complex ---------------------------------------


        cmd.append("-filter_complex \"").append(filterComplex).append("\" ")
                .append("-map \"[tmp").append(inputIndex - 1).append("]\" ")
                .append(audioMaps)
                .append("-c:v libx264 -preset ultrafast -y ").append(IOHelper.CombinePath(data.getProjectPath(), Constants.DEFAULT_PREVIEW_CLIP_FILENAME));

        System.err.println(cmd);

        return cmd.toString();

    }


    public static void generateExportVideo(Context context, EditingActivity.Timeline timeline, EditingActivity.VideoSettings settings, MainActivity.ProjectData data, Runnable onSuccess) {
        runAnyCommand(context, generateExportCmd(settings, timeline, data), onSuccess, () -> {
        }, new RunnableImpl() {
            @Override
            public <T> void runWithParam(T param) {

            }
        }, new RunnableImpl() {
            @Override
            public <T> void runWithParam(T param) {

            }
        });
    }

    public static String generateExportCmd(EditingActivity.VideoSettings settings, EditingActivity.Timeline timeline, MainActivity.ProjectData data) {
        StringBuilder cmd = new StringBuilder();
        cmd.append("-f lavfi -i color=c=black:s=")
                .append(settings.getVideoWidth()).append("x").append(settings.getVideoHeight())
                .append(":r=").append(settings.getFrameRate()).append(" -t ").append(timeline.duration).append(" ");

        StringBuilder filterComplex = new StringBuilder();
        StringBuilder audioInputs = new StringBuilder();
        StringBuilder audioMaps = new StringBuilder();

        int inputIndex = 0;
        int audioClipCount = 0;

        // --- Inserting file path into -i ---
        for (EditingActivity.Track track : timeline.tracks) {
            for (EditingActivity.Clip clip : track.clips) {

                switch (clip.type) {
                    case VIDEO:
                    case AUDIO:
                    case IMAGE:
                        cmd.append("-i \"").append(clip.filePath).append("\" ");
                        break;
                }
            }
        }


        // --- Inputting clips from -i ---
        filterComplex.append("[").append(inputIndex).append(":v]trim=duration=").append(timeline.duration).append(",setpts=PTS-STARTPTS[base];\n");
        inputIndex++;
        for (EditingActivity.Track track : timeline.tracks) {
            for (EditingActivity.Clip clip : track.clips) {

                String clipLabel = "[video-" + inputIndex + "]";
                String audioLabel = "[audio-" + inputIndex + "]";

                switch (clip.type) {
                    case VIDEO:
                    case IMAGE:
                        // 🖼️ Video/Image visual logic
                        filterComplex.append("[").append(inputIndex).append(":v]")
                                .append("scale=iw*").append(clip.scaleX).append(":ih*").append(clip.scaleY).append(",")
                                .append("rotate=").append(clip.rotation).append(":ow=rotw(").append(clip.rotation).append("):oh=roth(").append(clip.rotation).append("),")
                                .append("trim=start=").append(clip.startClipTrim).append(":end=").append(clip.startClipTrim + clip.duration).append(",")
                                .append("setpts=PTS-STARTPTS+").append(clip.startTime).append("/TB").append(clipLabel).append(";\n");
                        break;

                    case AUDIO:
                        // 🎵 Pure audio clip logic
                        int delayMs = (int) (clip.startTime * 1000);
                        filterComplex.append("[").append(inputIndex).append(":a]")
                                .append("atrim=start=").append(clip.startClipTrim).append(":end=").append(clip.startClipTrim + clip.duration).append(",")
                                .append("adelay=").append(delayMs).append("|").append(delayMs).append(",")
                                .append("asetpts=PTS-STARTPTS")
                                .append(audioLabel).append(";\n");

                        audioInputs.append(audioLabel);
                        audioClipCount++;
                        break;
                }

                // 🔊 Handle embedded audio in VIDEO
                if (clip.type == EditingActivity.ClipType.VIDEO) {
                    int delayMs = (int) (clip.startTime * 1000);
                    filterComplex.append("[").append(inputIndex).append(":a]")
                            .append("atrim=start=").append(clip.startClipTrim).append(":end=").append(clip.startClipTrim + clip.duration).append(",")
                            .append("adelay=").append(delayMs).append("|").append(delayMs).append(",")
                            .append("asetpts=PTS-STARTPTS")
                            .append(audioLabel).append(";\n");

                    audioInputs.append(audioLabel);
                    audioClipCount++;
                }

                switch (clip.type) {
                    case VIDEO:
                    case IMAGE:
                    case AUDIO:
                        inputIndex++;
                        break;
                }
            }
        }


        inputIndex = 1;


        for (EditingActivity.Track track : timeline.tracks) {
            for (EditingActivity.Clip clip : track.clips) {

                if (Objects.requireNonNull(clip.type) == EditingActivity.ClipType.EFFECT) {
                    if (clip.effect != null) {
                        filterComplex.append(FXCommandEmitter.emit(clip, inputIndex)).append("\n");
                    }
                }
            }
        }


        for (EditingActivity.Track track : timeline.tracks) {
            for (EditingActivity.Clip clip : track.clips) {

                String clipLabel = "[video-" + inputIndex + "]";
                String overlayLabel = inputIndex == 1 ? "[base]" : "[tmp" + (inputIndex - 1) + "]";
                String outLabel = "[tmp" + inputIndex + "]";

                switch (clip.type) {
                    case VIDEO:
                    case IMAGE:
                        filterComplex.append(overlayLabel).append(clipLabel)
                                .append("overlay=").append(clip.posX).append(":").append(clip.posY)
                                .append(":enable='between(t,")
                                .append(clip.startTime).append(",")
                                .append(clip.startTime + clip.duration).append(")'").append(outLabel).append(";\n");
                        break;
                    case EFFECT:
                        // --- Effects processed in the above code.
                        break;
                    case AUDIO:
                        // --- Further processing for audio goes here
                        break;
                    case TEXT:
                        filterComplex.append(overlayLabel)
                                .append("drawtext=").append("fontfile='/system/fonts/DroidSans.ttf'")
                                .append(":fontsize=").append(clip.fontSize)
                                .append(":text='").append(clip.textContent)
                                .append("':x=").append("(w-text_w)/2")//.append(clip.posX) Centralize text
                                .append(":y=").append("(h-text_h)/2")//.append(clip.posY) Centralize text
                                .append(":enable='between(t,").append(clip.startTime).append(",")
                                .append(clip.startTime + clip.duration).append(")'")
                                .append(outLabel).append(";\n");
                        break;
                }

                // 🔊 Handle embedded audio in VIDEO
                if (clip.type == EditingActivity.ClipType.VIDEO) {
                    // --- Further processing for audio goes here
                }

                if (clip.type != EditingActivity.ClipType.AUDIO)
                    inputIndex++;
            }
        }

        // 🔁 Mix audio if present
        if (audioClipCount > 0) {
            filterComplex.append(audioInputs)
                    .append("amix=inputs=").append(audioClipCount).append("[aout];\n");
            audioMaps.append("-map \"[aout]\" ");
        } else {
            audioMaps.append("-an "); // 🧘 No audio at all
        }

        cmd.append("-filter_complex \"").append(filterComplex).append("\" ")
                .append("-map \"[tmp").append(inputIndex - 1).append("]\" ")
                .append(audioMaps)
                .append("-c:v libx264 -preset ").append(settings.getPreset())
                .append(" -tune ").append(settings.getTune())
                .append(" -crf ").append(settings.getCRF())
                .append(" -y ").append(IOHelper.CombinePath(data.getProjectPath(), Constants.DEFAULT_EXPORT_CLIP_FILENAME));

        return cmd.toString();
    }
}